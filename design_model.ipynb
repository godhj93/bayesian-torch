{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31min planes is reduced by 1 times since the computation is heavy\u001b[0m\n",
      "\u001b[32mCIFAR-10 dataset is loaded\u001b[0m\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "from bayesian_torch.layers.variational_layers.conv_variational import Conv2dReparameterization, Conv2dReparameterization_Multivariate\n",
    "from torch.distributions import LowRankMultivariateNormal, kl_divergence\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from models import resnet20_multi\n",
    "from bayesian_torch.models.bayesian.resnet_variational import resnet20\n",
    "from bayesian_torch.layers.variational_layers.conv_variational import Conv2dReparameterization, Conv2dReparameterization_Multivariate\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from distill import get_conv_layers\n",
    "\n",
    "from bayesian_torch.models.deterministic.resnet import resnet20 as resnet20_deterministic\n",
    "dnn = resnet20_deterministic()\n",
    "dnn.load_state_dict(torch.load('runs/cifar/resnet20/reference/dnn/bs128_lr0.001_mc100_temp_1.0_ep300_kd_False_alpha_0.0_moped_False_20240820-012216/best_model.pth'))\n",
    "dnn.eval().cuda()\n",
    "from utils import get_dataset\n",
    "\n",
    "class opt:\n",
    "    \n",
    "    bs = 1\n",
    "    data = 'cifar'\n",
    "    multi_gpu = False\n",
    "    \n",
    "args = opt()\n",
    "train_loader, test_loader = get_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_conv_layers = get_conv_layers(dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ActivationDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.input_dir = os.path.join(folder_path, 'input')\n",
    "        self.output_dir = os.path.join(folder_path, 'output')\n",
    "        \n",
    "        # input과 output 디렉토리 안의 파일 목록을 가져옵니다.\n",
    "        self.input_files = sorted([f for f in os.listdir(self.input_dir) if f.endswith('.pt')])\n",
    "        self.output_files = sorted([f for f in os.listdir(self.output_dir) if f.endswith('.pt')])\n",
    "        \n",
    "        # input과 output 파일 수가 같은지 확인\n",
    "        assert len(self.input_files) == len(self.output_files), \"Input and output file counts do not match.\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # input과 output 파일 경로\n",
    "        input_path = os.path.join(self.input_dir, self.input_files[idx])\n",
    "        output_path = os.path.join(self.output_dir, self.output_files[idx])\n",
    "        \n",
    "        # 텐서 로드\n",
    "        input_tensor = torch.load(input_path)\n",
    "        output_tensor = torch.load(output_path)\n",
    "        \n",
    "        return input_tensor.squeeze(), output_tensor.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([432, 432])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 78.7698: 100%|██████████| 50000/50000 [04:30<00:00, 184.63it/s] \n",
      "loss: 59.7845: 100%|██████████| 50000/50000 [04:38<00:00, 179.43it/s]\n",
      "loss: 58.1929: 100%|██████████| 50000/50000 [05:17<00:00, 157.58it/s]\n",
      "loss: 57.7416: 100%|██████████| 50000/50000 [04:45<00:00, 175.37it/s]\n",
      "loss: 57.3269: 100%|██████████| 50000/50000 [05:03<00:00, 164.89it/s]\n",
      "loss: 57.0969: 100%|██████████| 50000/50000 [04:49<00:00, 172.97it/s]\n",
      "loss: 57.3523: 100%|██████████| 50000/50000 [04:31<00:00, 184.03it/s]\n",
      "loss: 57.0690: 100%|██████████| 50000/50000 [04:48<00:00, 173.59it/s]\n",
      "loss: 57.4338: 100%|██████████| 50000/50000 [04:39<00:00, 179.16it/s]\n",
      "loss: 56.9411: 100%|██████████| 50000/50000 [04:48<00:00, 173.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 44.20319366455078\n",
      "Model is saved at ./resent20_dnn_activations/layer_0/bnn_conv.pth\n",
      "torch.Size([2304, 2304])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 3709.2367: 100%|██████████| 50000/50000 [09:51<00:00, 84.55it/s] \n",
      "loss: 3707.3873: 100%|██████████| 50000/50000 [08:00<00:00, 104.10it/s]\n",
      "loss: 3688.2813: 100%|██████████| 50000/50000 [07:51<00:00, 106.15it/s]\n",
      "loss: 3684.0525: 100%|██████████| 50000/50000 [07:58<00:00, 104.50it/s]\n",
      "loss: 3671.9550: 100%|██████████| 50000/50000 [08:01<00:00, 103.88it/s]\n",
      "loss: 3665.1854: 100%|██████████| 50000/50000 [07:51<00:00, 105.97it/s]\n",
      "loss: 3662.6815: 100%|██████████| 50000/50000 [08:01<00:00, 103.76it/s]\n",
      "loss: 3657.1797: 100%|██████████| 50000/50000 [07:51<00:00, 105.95it/s]\n",
      "loss: 3653.5205: 100%|██████████| 50000/50000 [07:59<00:00, 104.26it/s]\n",
      "loss: 3661.1139: 100%|██████████| 50000/50000 [08:01<00:00, 103.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 5574.46875\n",
      "Model is saved at ./resent20_dnn_activations/layer_1/bnn_conv.pth\n",
      "torch.Size([2304, 2304])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2010.8336: 100%|██████████| 50000/50000 [07:53<00:00, 105.64it/s]\n",
      "loss: 1949.3453: 100%|██████████| 50000/50000 [07:59<00:00, 104.17it/s]\n",
      "loss: 1924.3887: 100%|██████████| 50000/50000 [07:51<00:00, 106.10it/s]\n",
      "loss: 1914.8476: 100%|██████████| 50000/50000 [07:56<00:00, 104.89it/s]\n",
      "loss: 1902.5399: 100%|██████████| 50000/50000 [08:01<00:00, 103.78it/s]\n",
      "loss: 1897.1404: 100%|██████████| 50000/50000 [07:51<00:00, 106.05it/s]\n",
      "loss: 1896.0950: 100%|██████████| 50000/50000 [07:59<00:00, 104.24it/s]\n",
      "loss: 1895.6970: 100%|██████████| 50000/50000 [07:51<00:00, 106.08it/s]\n",
      "loss: 1888.9905: 100%|██████████| 50000/50000 [07:58<00:00, 104.48it/s]\n",
      "loss: 1889.6985: 100%|██████████| 50000/50000 [07:59<00:00, 104.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 1351.16796875\n",
      "Model is saved at ./resent20_dnn_activations/layer_2/bnn_conv.pth\n",
      "torch.Size([2304, 2304])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6071.4449: 100%|██████████| 50000/50000 [09:13<00:00, 90.37it/s] \n",
      "loss: 5844.6180: 100%|██████████| 50000/50000 [08:00<00:00, 104.16it/s]\n",
      "loss: 5772.1042: 100%|██████████| 50000/50000 [07:51<00:00, 106.15it/s]\n",
      "loss: 5746.1960: 100%|██████████| 50000/50000 [07:58<00:00, 104.50it/s]\n",
      "loss: 5724.2914: 100%|██████████| 50000/50000 [08:00<00:00, 104.04it/s]\n",
      "loss: 5710.0627: 100%|██████████| 50000/50000 [07:51<00:00, 105.99it/s]\n",
      "loss: 5702.3644: 100%|██████████| 50000/50000 [07:58<00:00, 104.44it/s]\n",
      "loss: 5695.7414: 100%|██████████| 50000/50000 [07:50<00:00, 106.34it/s]\n",
      "loss: 5687.0096: 100%|██████████| 50000/50000 [07:59<00:00, 104.18it/s]\n",
      "loss: 5678.1555: 100%|██████████| 50000/50000 [08:01<00:00, 103.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 5138.1201171875\n",
      "Model is saved at ./resent20_dnn_activations/layer_3/bnn_conv.pth\n",
      "torch.Size([2304, 2304])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1442.1266: 100%|██████████| 50000/50000 [09:30<00:00, 87.57it/s] \n",
      "loss: 1359.9721: 100%|██████████| 50000/50000 [07:58<00:00, 104.47it/s]\n",
      "loss: 1336.5431: 100%|██████████| 50000/50000 [07:59<00:00, 104.26it/s]\n",
      "loss: 1326.0946: 100%|██████████| 50000/50000 [07:53<00:00, 105.60it/s]\n",
      "loss: 1322.9552: 100%|██████████| 50000/50000 [07:58<00:00, 104.47it/s]\n",
      "loss: 1315.1339: 100%|██████████| 50000/50000 [07:52<00:00, 105.91it/s]\n",
      "loss: 1315.4237: 100%|██████████| 50000/50000 [08:00<00:00, 104.00it/s]\n",
      "loss: 1314.0154: 100%|██████████| 50000/50000 [07:59<00:00, 104.35it/s]\n",
      "loss: 1311.3301: 100%|██████████| 50000/50000 [07:55<00:00, 105.18it/s]\n",
      "loss: 1312.0714: 100%|██████████| 50000/50000 [07:58<00:00, 104.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 1505.867919921875\n",
      "Model is saved at ./resent20_dnn_activations/layer_4/bnn_conv.pth\n",
      "torch.Size([2304, 2304])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 9445.0994: 100%|██████████| 50000/50000 [07:52<00:00, 105.74it/s]\n",
      "loss: 9093.0753: 100%|██████████| 50000/50000 [08:00<00:00, 104.01it/s]\n",
      "loss: 8974.5259: 100%|██████████| 50000/50000 [07:57<00:00, 104.81it/s]\n",
      "loss: 8927.3250: 100%|██████████| 50000/50000 [07:56<00:00, 104.99it/s]\n",
      "loss: 8887.8082: 100%|██████████| 50000/50000 [08:00<00:00, 104.03it/s]\n",
      "loss: 8873.2267: 100%|██████████| 50000/50000 [07:52<00:00, 105.83it/s]\n",
      "loss: 8857.0239: 100%|██████████| 50000/50000 [08:01<00:00, 103.91it/s]\n",
      "loss: 8839.5399: 100%|██████████| 50000/50000 [07:59<00:00, 104.29it/s]\n",
      "loss: 8830.6269: 100%|██████████| 50000/50000 [07:56<00:00, 104.98it/s]\n",
      "loss: 8825.7964: 100%|██████████| 50000/50000 [08:01<00:00, 103.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 13256.55859375\n",
      "Model is saved at ./resent20_dnn_activations/layer_5/bnn_conv.pth\n",
      "torch.Size([2304, 2304])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 447.2029: 100%|██████████| 50000/50000 [10:11<00:00, 81.71it/s]\n",
      "loss: 402.3396: 100%|██████████| 50000/50000 [07:59<00:00, 104.18it/s]\n",
      "loss: 395.2875: 100%|██████████| 50000/50000 [07:58<00:00, 104.58it/s]\n",
      "loss: 392.9135: 100%|██████████| 50000/50000 [07:53<00:00, 105.58it/s]\n",
      "loss: 392.4688: 100%|██████████| 50000/50000 [08:01<00:00, 103.91it/s]\n",
      "loss: 391.6206: 100%|██████████| 50000/50000 [07:51<00:00, 105.95it/s]\n",
      "loss: 391.6076: 100%|██████████| 50000/50000 [07:58<00:00, 104.39it/s]\n",
      "loss: 391.0088: 100%|██████████| 50000/50000 [08:01<00:00, 103.94it/s]\n",
      "loss: 391.4956: 100%|██████████| 50000/50000 [07:54<00:00, 105.39it/s]\n",
      "loss: 391.5485: 100%|██████████| 50000/50000 [07:59<00:00, 104.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 155.01199340820312\n",
      "Model is saved at ./resent20_dnn_activations/layer_6/bnn_conv.pth\n",
      "torch.Size([4608, 4608])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 29711.9826: 100%|██████████| 50000/50000 [21:18<00:00, 39.10it/s]\n",
      "loss: 29975.3507: 100%|██████████| 50000/50000 [20:28<00:00, 40.70it/s]\n",
      "loss: 29829.2050: 100%|██████████| 50000/50000 [20:29<00:00, 40.66it/s]\n",
      "loss: 29719.1694: 100%|██████████| 50000/50000 [20:24<00:00, 40.84it/s]\n",
      "loss: 29627.6091: 100%|██████████| 50000/50000 [20:34<00:00, 40.51it/s]\n",
      "loss: 29595.2512: 100%|██████████| 50000/50000 [20:32<00:00, 40.58it/s]\n",
      "loss: 29568.1697: 100%|██████████| 50000/50000 [20:29<00:00, 40.68it/s]\n",
      "loss: 29532.1396: 100%|██████████| 50000/50000 [20:36<00:00, 40.45it/s]\n",
      "loss: 29515.5506: 100%|██████████| 50000/50000 [20:36<00:00, 40.44it/s]\n",
      "loss: 29514.1017: 100%|██████████| 50000/50000 [20:37<00:00, 40.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 36483.55078125\n",
      "Model is saved at ./resent20_dnn_activations/layer_7/bnn_conv.pth\n",
      "torch.Size([9216, 9216])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 151504.2387: 100%|██████████| 50000/50000 [1:45:54<00:00,  7.87it/s]\n",
      "loss: 168547.8724: 100%|██████████| 50000/50000 [1:44:56<00:00,  7.94it/s]\n",
      "loss: 171101.6469: 100%|██████████| 50000/50000 [1:44:55<00:00,  7.94it/s]\n",
      "loss: 172006.5133: 100%|██████████| 50000/50000 [1:44:23<00:00,  7.98it/s]\n",
      "loss: 172750.5400: 100%|██████████| 50000/50000 [1:44:55<00:00,  7.94it/s]\n",
      "loss: 172995.7821: 100%|██████████| 50000/50000 [1:44:10<00:00,  8.00it/s]\n",
      "loss: 173203.6622: 100%|██████████| 50000/50000 [1:44:03<00:00,  8.01it/s]\n",
      "loss: 173448.3614: 100%|██████████| 50000/50000 [1:43:50<00:00,  8.02it/s]\n",
      "loss: 173417.9080: 100%|██████████| 50000/50000 [1:43:37<00:00,  8.04it/s]\n",
      "loss: 173415.1385: 100%|██████████| 50000/50000 [1:43:22<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 154126.359375\n",
      "Model is saved at ./resent20_dnn_activations/layer_8/bnn_conv.pth\n",
      "torch.Size([9216, 9216])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1383507.5586: 100%|██████████| 50000/50000 [1:46:37<00:00,  7.82it/s]\n",
      "loss: 1539172.0272: 100%|██████████| 50000/50000 [1:43:11<00:00,  8.08it/s]\n",
      "loss: 1567988.0417: 100%|██████████| 50000/50000 [1:43:42<00:00,  8.03it/s]\n",
      "loss: 1576502.4458: 100%|██████████| 50000/50000 [1:43:42<00:00,  8.03it/s]\n",
      "loss: 1583301.3976: 100%|██████████| 50000/50000 [1:44:24<00:00,  7.98it/s]\n",
      "loss: 1587869.2171: 100%|██████████| 50000/50000 [1:42:00<00:00,  8.17it/s]\n",
      "loss: 1588327.9222: 100%|██████████| 50000/50000 [1:41:01<00:00,  8.25it/s]\n",
      "loss: 1591407.8535: 100%|██████████| 50000/50000 [1:41:24<00:00,  8.22it/s]\n",
      "loss: 1591050.0882: 100%|██████████| 50000/50000 [1:41:47<00:00,  8.19it/s]\n",
      "loss: 1590601.7388: 100%|██████████| 50000/50000 [1:41:52<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 969103.75\n",
      "Model is saved at ./resent20_dnn_activations/layer_9/bnn_conv.pth\n",
      "torch.Size([9216, 9216])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 60924.3784: 100%|██████████| 50000/50000 [1:47:13<00:00,  7.77it/s]\n",
      "loss: 70443.3005: 100%|██████████| 50000/50000 [1:45:49<00:00,  7.87it/s]\n",
      "loss: 71415.1004: 100%|██████████| 50000/50000 [1:44:48<00:00,  7.95it/s]\n",
      "loss: 71950.1945: 100%|██████████| 50000/50000 [1:44:44<00:00,  7.96it/s]\n",
      "loss: 71850.5246: 100%|██████████| 50000/50000 [1:43:06<00:00,  8.08it/s]\n",
      "loss: 72077.4082: 100%|██████████| 50000/50000 [1:42:12<00:00,  8.15it/s]\n",
      "loss: 71939.3226: 100%|██████████| 50000/50000 [1:42:24<00:00,  8.14it/s]\n",
      "loss: 71900.5463: 100%|██████████| 50000/50000 [1:43:01<00:00,  8.09it/s]\n",
      "loss: 71934.9303: 100%|██████████| 50000/50000 [1:43:27<00:00,  8.06it/s]\n",
      "loss: 71873.9916: 100%|██████████| 50000/50000 [1:48:43<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 107688.640625\n",
      "Model is saved at ./resent20_dnn_activations/layer_10/bnn_conv.pth\n",
      "torch.Size([9216, 9216])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1318677.7827:  92%|█████████▏| 46088/50000 [1:36:25<08:45,  7.44it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "for layer_idx, layer in enumerate(dnn_conv_layers):\n",
    "    bnn = Conv2dReparameterization_Multivariate(\n",
    "        in_channels=layer.in_channels,\n",
    "        out_channels=layer.out_channels,\n",
    "        kernel_size=layer.kernel_size[0],\n",
    "        stride=layer.stride,\n",
    "        padding=layer.padding,\n",
    "        dilation=layer.dilation,\n",
    "        groups=layer.groups,\n",
    "        bias=False,\n",
    "        rank = 'full'        \n",
    "    )\n",
    "    folder_path = f'./resent20_dnn_activations/layer_{layer_idx}'\n",
    "    \n",
    "    # Dataset과 DataLoader 생성\n",
    "    dataset = ActivationDataset(folder_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # DataLoader를 통해 데이터 확인\n",
    "    optimizer = torch.optim.Adam(bnn.parameters(), lr=1e-3)\n",
    "    bnn = bnn.cuda().train()\n",
    "    print(bnn.L_param.shape)\n",
    "    for e in range(10):\n",
    "        \n",
    "        pbar = tqdm(dataloader, total=len(dataloader), desc=f\"Epoch {e+1}\")\n",
    "        losses = []\n",
    "        for inputs, outputs in pbar:\n",
    "            inputs, outputs = inputs.cuda(), outputs.cuda()\n",
    "            output_bnn , _ = bnn(inputs)\n",
    "            \n",
    "            loss = F.mse_loss(output_bnn, outputs, reduction='mean')\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            pbar.set_description(f\"loss: {np.mean(losses):.4f}\")\n",
    "            \n",
    "    optimizer = torch.optim.LBFGS(bnn.parameters())\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        output_bnn , _ = bnn(inputs)\n",
    "        loss = F.mse_loss(output_bnn, outputs, reduction='mean')\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    \n",
    "    optimizer.step(closure)\n",
    "    print(f\"Final loss: {loss.item()}\")\n",
    "    \n",
    "    torch.save(bnn.state_dict(), f'./resent20_dnn_activations/layer_{layer_idx}/bnn_conv.pth')\n",
    "    print(f\"Model is saved at ./resent20_dnn_activations/layer_{layer_idx}/bnn_conv.pth\")\n",
    "    # break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_covariance(layer, i, save = False, file_name = None):\n",
    "    \n",
    "    mu = layer.mu_kernel.view(-1)\n",
    "    L, D = layer.get_covariance_param()\n",
    "    \n",
    "    mvn = LowRankMultivariateNormal(mu, L, D)\n",
    "    \n",
    "    # plt.imshow(mvn.covariance_matrix.cpu().detach().numpy()[:9*i, :9*i])\n",
    "    # plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    \n",
    "    if save:\n",
    "        torch.save(layer.state_dict(), file_name)\n",
    "    \n",
    "    return mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvn_list = []\n",
    "\n",
    "for layer_idx, layer in tqdm(enumerate(dnn_conv_layers), total = len(dnn_conv_layers)):\n",
    "    bnn_test = Conv2dReparameterization_Multivariate(\n",
    "        in_channels=layer.in_channels,\n",
    "        out_channels=layer.out_channels,\n",
    "        kernel_size=layer.kernel_size[0],\n",
    "        stride=layer.stride,\n",
    "        padding=layer.padding,\n",
    "        dilation=layer.dilation,\n",
    "        groups=layer.groups,\n",
    "        bias=False,\n",
    "        rank = 'full'        \n",
    "    )\n",
    "    folder_path = f'./resent20_dnn_activations/layer_{layer_idx}'\n",
    "    \n",
    "    bnn_test.load_state_dict(torch.load(f'./resent20_dnn_activations/layer_{layer_idx}/bnn_conv.pth'))\n",
    "    \n",
    "    mvn_list.append(visualize_covariance(bnn_test, 5, save = False, file_name = f'./resent20_dnn_activations/layer_{layer_idx}/bnn_conv_cov.pth'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 100))\n",
    "for idx in range(len(mvn_list)):\n",
    "    i=6\n",
    "    plt.subplot(len(mvn_list), 1, idx+1)\n",
    "    plt.imshow(mvn_list[idx].covariance_matrix.cpu().detach().numpy()[:9*i, :9*i])\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
