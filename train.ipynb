{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9848, 0.046528087556362153)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import LeNet_BNN, LeNet_BNN_uni, LeNet\n",
    "from utils import train_BNN, train_DNN, test_BNN, test_DNN\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dnn = LeNet()\n",
    "dnn.load_state_dict(torch.load('runs/dnn_bs1024_lr0.001_mc100_temp_1.0_ep100_20240711-160323/best_model.pth'))\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./data/', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1024, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1024, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_DNN(dnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bnn_uni = LeNet_BNN_uni().to(device)\n",
    "# bnn_uni.load_state_dict(torch.load('bnn_uni.pth'))\n",
    "# # train_BNN(10, bnn_uni)\n",
    "# test_BNN(bnn_uni, test_loader, 100, 1024, 'cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mu$, $\\sigma$ 학습 가능한지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "target_w = 3.0\n",
    "\n",
    "# Sample the weights\n",
    "mu = torch.nn.Parameter(torch.Tensor(1))\n",
    "sigma = torch.nn.Parameter(torch.Tensor(1))\n",
    "mu.data.normal_(0, 0.1)\n",
    "sigma.data.normal_(1, 0.1)\n",
    "\n",
    "w_dist = Normal(mu,sigma)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam([mu, sigma], lr=0.01)\n",
    "\n",
    "# Log for plotting\n",
    "mu_log = []\n",
    "sigma_log = []\n",
    "\n",
    "# Sample the weights\n",
    "for epoch in range(1000):\n",
    "    w = w_dist.rsample()\n",
    "    \n",
    "    loss_val = loss(w, torch.Tensor([target_w]))\n",
    "    optimizer.zero_grad()\n",
    "    loss_val.backward()\n",
    "    optimizer.step()\n",
    "    mu_log.append(mu.item())\n",
    "    sigma_log.append(sigma.item())\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(mu_log)\n",
    "plt.plot(sigma_log)\n",
    "plt.grid()\n",
    "plt.legend(['mu', 'sigma'])\n",
    "\n",
    "# plot target\n",
    "plt.plot([0,1000], [target_w, target_w], 'r--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 모델의 가중치를 분포로 학습가능한지 확인 $w_i \\sim \\mathbf{N}(\\mu_i,\\sigma_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w_conv1_dnn = dnn.conv1.weight.data\n",
    "\n",
    "# Sample the weights\n",
    "mu = torch.nn.Parameter(torch.zeros_like(w_conv1_dnn))\n",
    "sigma = torch.nn.Parameter(torch.ones_like(w_conv1_dnn))\n",
    "\n",
    "w_dist = Normal(mu,sigma)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam([mu, sigma], lr=0.01)\n",
    "\n",
    "# Log for plotting\n",
    "mu_log = []\n",
    "sigma_log = []\n",
    "losses = []\n",
    "for epoch in tqdm(range(1000)):\n",
    "    w = w_dist.rsample()\n",
    "    \n",
    "    loss_val = loss(w, w_conv1_dnn)\n",
    "    optimizer.zero_grad()\n",
    "    loss_val.backward()\n",
    "    optimizer.step()\n",
    "    mu_log.append(mu.mean().item())\n",
    "    sigma_log.append(sigma.mean().item())\n",
    "    losses.append(loss_val.item())\n",
    "    \n",
    "# plot training progress\n",
    "plt.plot(losses)\n",
    "plt.plot(mu_log)\n",
    "plt.plot(sigma_log)\n",
    "plt.grid()\n",
    "plt.legend(['loss', 'mu', 'sigma'])\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# 예시 데이터, 실제 데이터로 대체하세요.\n",
    "mu_kernel = mu  # 실제 mu_kernel 값으로 대체\n",
    "rho_kernel = sigma  # 실제 rho_kernel 값으로 대체\n",
    "w_dnn = dnn.conv1.weight.data\n",
    "# sigma_weight 계산\n",
    "sigma_weight = torch.log1p(torch.exp(rho_kernel))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for idx, (w_target, mu, sigma) in enumerate(zip(w_dnn, mu_kernel, sigma_weight)):\n",
    "    \n",
    "    print(w_target.shape, mu.shape, sigma.shape)\n",
    "    w_target = w_target.cpu().detach().numpy()\n",
    "    plt.subplot(6,1, idx+1)\n",
    "    for i in range(3):\n",
    "        \n",
    "        for j in range(3):\n",
    "            \n",
    "            plt.axvline(x=w_target[0,i,j], color='r', linestyle='--', label='target')\n",
    "            \n",
    "            x = np.linspace(mu[0,i,j].item() - 3 * sigma[0,i,j].item(), mu[0,i,j].item() + 3 * sigma[0,i,j].item(), 1000)\n",
    "            pdf = norm.pdf(x, loc=mu[0,i,j].item(), scale= sigma[0,i,j].item())\n",
    "            # plt.subplot(3,3,i+j+1)\n",
    "\n",
    "            plt.plot(x, pdf, label=f'N({mu[0,i,j].item():.2f}, {sigma[0,i,j].item():.2f})')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 만약 입력 X까지 고려한 출력 y를 loss로 사용한다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_uni = LeNet_BNN_uni().to(device)\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(bnn_uni.conv1.parameters(), lr=0.01)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for e in range(10):\n",
    "    for x,y in tqdm(train_loader):\n",
    "        \n",
    "        y_bnn, _ = bnn_uni.conv1.forward(x.to(device))\n",
    "        \n",
    "            \n",
    "        y_dnn = dnn.conv1.forward(x.to(device))\n",
    "\n",
    "        loss_val = loss(y_bnn, y_dnn)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss_val.item())\n",
    "    \n",
    "\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.grid()\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# 예시 데이터, 실제 데이터로 대체하세요.\n",
    "mu_kernel = bnn_uni.conv1.mu_kernel  # 실제 mu_kernel 값으로 대체\n",
    "rho_kernel = bnn_uni.conv1.rho_kernel  # 실제 rho_kernel 값으로 대체\n",
    "w_dnn = dnn.conv1.weight.data\n",
    "# sigma_weight 계산\n",
    "sigma_weight = torch.log1p(torch.exp(rho_kernel))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for idx, (w_target, mu, sigma) in enumerate(zip(w_dnn, mu_kernel, sigma_weight)):\n",
    "    \n",
    "    print(w_target.shape, mu.shape, sigma.shape)\n",
    "    w_target = w_target.cpu().detach().numpy()\n",
    "    plt.subplot(6,1, idx+1)\n",
    "    for i in range(3):\n",
    "        \n",
    "        for j in range(3):\n",
    "            \n",
    "            plt.axvline(x=w_target[0,i,j], color='r', linestyle='--', label='target')\n",
    "            \n",
    "            x = np.linspace(mu[0,i,j].item() - 3 * sigma[0,i,j].item(), mu[0,i,j].item() + 3 * sigma[0,i,j].item(), 1000)\n",
    "            pdf = norm.pdf(x, loc=mu[0,i,j].item(), scale= sigma[0,i,j].item())\n",
    "            # plt.subplot(3,3,i+j+1)\n",
    "\n",
    "            plt.plot(x, pdf, label=f'N({mu[0,i,j].item():.2f}, {sigma[0,i,j].item():.2f})')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aleatoric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_uni = LeNet_BNN_uni().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w_conv1_dnn = dnn.conv1.weight.data\n",
    "\n",
    "# Sample the weights\n",
    "\n",
    "# loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam([bnn_uni.conv1.mu_kernel, bnn_uni.conv1.rho_kernel], lr=1e-3)\n",
    "\n",
    "# Log for plotting\n",
    "mu_log = []\n",
    "sigma_log = []\n",
    "losses = []\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    mu = bnn_uni.conv1.mu_kernel\n",
    "    sigma = torch.log1p(torch.exp(bnn_uni.conv1.rho_kernel))\n",
    "\n",
    "    loss_val = 0.5 * torch.mean((mu - w_conv1_dnn)**2 / sigma + sigma )\n",
    "        \n",
    "        \n",
    "    \n",
    "    # loss_val = loss(w, w_conv1_dnn)\n",
    "    optimizer.zero_grad()\n",
    "    loss_val.backward()\n",
    "    optimizer.step()\n",
    "    mu_log.append(mu.mean().item())\n",
    "    sigma_log.append(sigma.mean().item())\n",
    "    losses.append(loss_val.item())\n",
    "    \n",
    "# plot training progress\n",
    "plt.plot(losses)\n",
    "plt.plot(mu_log)\n",
    "plt.plot(sigma_log)\n",
    "plt.grid()\n",
    "plt.legend(['loss', 'mu', 'sigma'])\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# 예시 데이터, 실제 데이터로 대체하세요.\n",
    "mu_kernel = bnn_uni.conv1.mu_kernel  # 실제 mu_kernel 값으로 대체\n",
    "rho_kernel = bnn_uni.conv1.rho_kernel  # 실제 rho_kernel 값으로 대체\n",
    "w_dnn = dnn.conv1.weight.data\n",
    "# sigma_weight 계산\n",
    "sigma_weight = torch.log1p(torch.exp(rho_kernel))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for idx, (w_target, mu, sigma) in enumerate(zip(w_dnn, mu_kernel, sigma_weight)):\n",
    "    \n",
    "    print(w_target.shape, mu.shape, sigma.shape)\n",
    "    w_target = w_target.cpu().detach().numpy()\n",
    "    plt.subplot(6,1, idx+1)\n",
    "    for i in range(3):\n",
    "        \n",
    "        for j in range(3):\n",
    "            \n",
    "            plt.axvline(x=w_target[0,i,j], color='r', linestyle='--', label='target')\n",
    "            \n",
    "            x = np.linspace(mu[0,i,j].item() - 3 * sigma[0,i,j].item(), mu[0,i,j].item() + 3 * sigma[0,i,j].item(), 1000)\n",
    "            pdf = norm.pdf(x, loc=mu[0,i,j].item(), scale= sigma[0,i,j].item())\n",
    "            # plt.subplot(3,3,i+j+1)\n",
    "\n",
    "            plt.plot(x, pdf, label=f'N({mu[0,i,j].item():.2f}, {sigma[0,i,j].item():.2f})')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w_conv2_dnn = dnn.conv2.weight.data\n",
    "\n",
    "# Sample the weights\n",
    "\n",
    "# loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam([bnn_uni.conv2.mu_kernel, bnn_uni.conv2.rho_kernel], lr=1e-3)\n",
    "\n",
    "# Log for plotting\n",
    "mu_log = []\n",
    "sigma_log = []\n",
    "losses = []\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    mu = bnn_uni.conv2.mu_kernel\n",
    "    sigma = torch.log1p(torch.exp(bnn_uni.conv2.rho_kernel))\n",
    "\n",
    "    loss_val = 0.5 * torch.mean((mu - w_conv2_dnn)**2 / sigma + sigma )\n",
    "        \n",
    "        \n",
    "    \n",
    "    # loss_val = loss(w, w_conv2_dnn)\n",
    "    optimizer.zero_grad()\n",
    "    loss_val.backward()\n",
    "    optimizer.step()\n",
    "    mu_log.append(mu.mean().item())\n",
    "    sigma_log.append(sigma.mean().item())\n",
    "    losses.append(loss_val.item())\n",
    "    \n",
    "# plot training progress\n",
    "plt.plot(losses)\n",
    "plt.plot(mu_log)\n",
    "plt.plot(sigma_log)\n",
    "plt.grid()\n",
    "plt.legend(['loss', 'mu', 'sigma'])\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# 예시 데이터, 실제 데이터로 대체하세요.\n",
    "mu_kernel = bnn_uni.conv2.mu_kernel  # 실제 mu_kernel 값으로 대체\n",
    "print(mu_kernel.shape)\n",
    "rho_kernel = bnn_uni.conv2.rho_kernel  # 실제 rho_kernel 값으로 대체\n",
    "w_dnn = dnn.conv2.weight.data\n",
    "# sigma_weight 계산\n",
    "sigma_weight = torch.log1p(torch.exp(rho_kernel))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for idx, (w_target, mu, sigma) in enumerate(zip(w_dnn, mu_kernel, sigma_weight)):\n",
    "    \n",
    "    print(w_target.shape, mu.shape, sigma.shape)\n",
    "    w_target = w_target.cpu().detach().numpy()\n",
    "    plt.subplot(16,1, idx+1)\n",
    "    for i in range(3):\n",
    "        \n",
    "        for j in range(3):\n",
    "            \n",
    "            plt.axvline(x=w_target[0,i,j], color='r', linestyle='--', label='target')\n",
    "            \n",
    "            x = np.linspace(mu[0,i,j].item() - 3 * sigma[0,i,j].item(), mu[0,i,j].item() + 3 * sigma[0,i,j].item(), 1000)\n",
    "            pdf = norm.pdf(x, loc=mu[0,i,j].item(), scale= sigma[0,i,j].item())\n",
    "            # plt.subplot(3,3,i+j+1)\n",
    "\n",
    "            plt.plot(x, pdf, label=f'N({mu[0,i,j].item():.2f}, {sigma[0,i,j].item():.2f})')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Prior distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_new = LeNet_BNN_uni().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_new.conv1.prior_mean, bnn_new.conv1.prior_variance, bnn_new.conv2.prior_mean, bnn_new.conv2.prior_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bnn_new.conv1.prior_mean = bnn_uni.conv1.mu_kernel.detach().clone()\n",
    "# bnn_new.conv1.prior_variance = torch.log1p(torch.exp(bnn_uni.conv1.rho_kernel)).detach().clone()\n",
    "\n",
    "# bnn_new.conv2.prior_mean = bnn_uni.conv2.mu_kernel.detach().clone()\n",
    "# bnn_new.conv2.prior_variance = torch.log1p(torch.exp(bnn_uni.conv2.rho_kernel)).detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_new.conv1.prior_weight_mu = bnn_uni.conv1.mu_kernel.detach().clone()\n",
    "bnn_new.conv1.prior_weight_sigma = torch.log1p(torch.exp(bnn_uni.conv1.rho_kernel)).detach().clone()\n",
    "\n",
    "bnn_new.conv2.prior_weight_mu = bnn_uni.conv2.mu_kernel.detach().clone()\n",
    "bnn_new.conv2.prior_weight_sigma = torch.log1p(torch.exp(bnn_uni.conv2.rho_kernel)).detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# class args:\n",
    "#     pass\n",
    "# args = args()\n",
    "# args.t = 1.0\n",
    "# writer = SummaryWriter(f'runs/bnn_new2')\n",
    "# train_BNN(epoch= 100, model = bnn_new, train_loader= train_loader, test_loader= test_loader, optimizer= optim.Adam(bnn_new.parameters(), lr=1e-3), writer = writer, mc_runs = 100, bs = 1024, device = 'cuda', args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bayesian_torch.models.dnn_to_bnn import dnn_to_bnn, get_kl_loss\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# bnn_rho_init = -3.0\n",
    "# moped_delta_factor = 0.2\n",
    "# const_bnn_prior_parameters = {\n",
    "#         \"prior_mu\": 0.0,\n",
    "#         \"prior_sigma\": 1.0,\n",
    "#         \"posterior_mu_init\": 0.0,\n",
    "#         \"posterior_rho_init\": bnn_rho_init,\n",
    "#         \"type\": \"Reparameterization\",  # Flipout or Reparameterization\n",
    "#         \"moped_enable\": True,  # initialize mu/sigma from the dnn weights\n",
    "#         \"moped_delta\": moped_delta_factor,\n",
    "#     }\n",
    "\n",
    "\n",
    "# dnn_moped = LeNet()\n",
    "# dnn_moped.load_state_dict(torch.load('runs/dnn_bs1024_lr0.001_mc100_temp_1.0_ep100_20240711-160323/best_model.pth'))\n",
    "\n",
    "# dnn_to_bnn(dnn_moped, const_bnn_prior_parameters)\n",
    "\n",
    "# class args:\n",
    "#     pass\n",
    "\n",
    "# args = args()\n",
    "# args.t = 1.0\n",
    "# writer = SummaryWriter(f'runs/dnn_moped2')\n",
    "# train_BNN(epoch= 100, model = dnn_moped.cuda(), train_loader= train_loader, test_loader= test_loader, optimizer= optim.Adam(dnn_moped.parameters(), lr=1e-3), writer = writer, mc_runs = 100, bs = 1024, device = 'cuda', args=args, moped=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multivariate Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### covariance matrix 학습 가능한지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matrix = torch.eye(10, requires_grad=True)\n",
    "\n",
    "L_init = torch.tril(torch.rand(10,10))\n",
    "L = nn.Parameter(L_init)\n",
    "\n",
    "optimizer = optim.Adam([L], lr=1e-2)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    loss = 0.5 * torch.sum((L.T @ L - target_matrix)**2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "plt.plot(losses)\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((L.T@L).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bnn_multi = LeNet_BNN().to(device)\n",
    "\n",
    "import copy\n",
    "cov_not_optimized = bnn_multi.conv1.get_covariance_matrix().cpu().detach().numpy()  \n",
    "print(cov_not_optimized.shape)\n",
    "optimizer = optim.Adam([bnn_multi.conv1.mu_kernel, bnn_multi.conv1.L_param], lr=1e-2)\n",
    "\n",
    "mu_log = []\n",
    "losses = []\n",
    "mean_loss = []\n",
    "for idx, _ in tqdm(enumerate(range(10000))):\n",
    "    w_conv1_dnn = dnn.conv1.weight.data.to(device)\n",
    "    c_in, c_out, k, _ = w_conv1_dnn.size()\n",
    "    \n",
    "    mu = bnn_multi.conv1.mu_kernel\n",
    "    mu_flat = mu.view(-1)\n",
    "    w_flat = w_conv1_dnn.view(-1)\n",
    "\n",
    "    epslion = 1e-6\n",
    "    cov = bnn_multi.conv1.get_covariance_matrix() + epslion * torch.eye(c_in * c_out * k * k).to(device)\n",
    "    \n",
    "    # Sampling the weight\n",
    "    w = torch.distributions.MultivariateNormal(mu_flat, cov).rsample().reshape(c_in, c_out, k, k)\n",
    "    \n",
    "    # k_value = torch.tensor(k, dtype=torch.float32).to(device)\n",
    "    # pi_value = torch.tensor(torch.pi, dtype=torch.float32).to(device)\n",
    "    # nnl = 0.5 * (k_value * torch.log(2 * pi_value) + torch.logdet(cov) + (w_flat - mu_flat).t() @ torch.inverse(cov) @ (w_flat - mu_flat))\n",
    "\n",
    "    nnl = (w - w_conv1_dnn).pow(2).mean()\n",
    "    optimizer.zero_grad()\n",
    "    nnl.backward()  # Do not use retain_graph=True\n",
    "    optimizer.step()\n",
    "\n",
    "    mu_log.append(mu.mean().item())\n",
    "    \n",
    "    losses.append(nnl.item())\n",
    "    \n",
    "    mean_loss.append(np.mean(losses))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(cov_not_optimized[:9,:9])\n",
    "plt.title('Covariance matrix (not optimized)')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "i=1\n",
    "plt.imshow(bnn_multi.conv1.get_covariance_matrix().cpu().detach().numpy()[:,:][:9*i,:9*i])\n",
    "plt.title('Covariance matrix (optimized)')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(mean_loss[:])\n",
    "plt.grid()\n",
    "plt.title('Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample the weights\n",
    "weight_dist = torch.distributions.MultivariateNormal(\n",
    "    bnn_multi.conv1.mu_kernel.view(-1),\n",
    "    bnn_multi.conv1.get_covariance_matrix() + epslion * torch.eye(c_in * c_out * k * k).to(device)\n",
    ")\n",
    "\n",
    "w_bnn = weight_dist.rsample().reshape(6, 1, 3, 3).view(-1)\n",
    "w_dnn = dnn.conv1.weight.data.view(-1)\n",
    "\n",
    "# Visualize the difference using vertical lines\n",
    "plt.figure(figsize=(10, 5))\n",
    "x = range(len(w_dnn.cpu().detach().numpy()))\n",
    "\n",
    "# # Plot DNN weights with thicker lines\n",
    "# plt.vlines(x, ymin=0, ymax=w_dnn.cpu().detach().numpy(), color='r', linewidth=3, label='DNN')\n",
    "\n",
    "# # Plot BNN weights with thinner lines\n",
    "# plt.vlines(x, ymin=0, ymax=w_bnn.cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "# Plot differences\n",
    "\n",
    "plt.vlines(x, ymin=0, ymax=(w_dnn.cpu().detach() - w_bnn.cpu().detach()).abs(), color='g', linewidth=1, label='DNN - BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Learned)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Diff (abs)')\n",
    "plt.ylim(0,3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cov randomly initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bnn_multi = LeNet_BNN().to(device)\n",
    "\n",
    "import copy\n",
    "cov_not_optimized = bnn_multi.conv1.get_covariance_matrix().cpu().detach().numpy()  \n",
    "print(cov_not_optimized.shape)\n",
    "optimizer = optim.Adam([bnn_multi.conv1.mu_kernel], lr=1e-2)\n",
    "\n",
    "mu_log = []\n",
    "losses = []\n",
    "mean_loss = []\n",
    "for idx, _ in tqdm(enumerate(range(10000))):\n",
    "    w_conv1_dnn = dnn.conv1.weight.data.to(device)\n",
    "    c_in, c_out, k, _ = w_conv1_dnn.size()\n",
    "    \n",
    "    mu = bnn_multi.conv1.mu_kernel\n",
    "    mu_flat = mu.view(-1)\n",
    "    w_flat = w_conv1_dnn.view(-1)\n",
    "\n",
    "    epslion = 1e-6\n",
    "    cov = bnn_multi.conv1.get_covariance_matrix() + epslion * torch.eye(c_in * c_out * k * k).to(device)\n",
    "    \n",
    "    # Sampling the weight\n",
    "    w = torch.distributions.MultivariateNormal(mu_flat, cov).rsample().reshape(c_in, c_out, k, k)\n",
    "    \n",
    "    # k_value = torch.tensor(k, dtype=torch.float32).to(device)\n",
    "    # pi_value = torch.tensor(torch.pi, dtype=torch.float32).to(device)\n",
    "    # nnl = 0.5 * (k_value * torch.log(2 * pi_value) + torch.logdet(cov) + (w_flat - mu_flat).t() @ torch.inverse(cov) @ (w_flat - mu_flat))\n",
    "\n",
    "    nnl = (w - w_conv1_dnn).pow(2).mean()\n",
    "    optimizer.zero_grad()\n",
    "    nnl.backward()  # Do not use retain_graph=True\n",
    "    optimizer.step()\n",
    "\n",
    "    mu_log.append(mu.mean().item())\n",
    "    \n",
    "    losses.append(nnl.item())\n",
    "    \n",
    "    mean_loss.append(np.mean(losses))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(cov_not_optimized[:9,:9])\n",
    "plt.title('Covariance matrix (not optimized)')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "i=1\n",
    "plt.imshow(bnn_multi.conv1.get_covariance_matrix().cpu().detach().numpy()[:,:][:9*i,:9*i])\n",
    "plt.title('Covariance matrix (optimized)')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(mean_loss[:])\n",
    "plt.grid()\n",
    "plt.title('Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample the weights\n",
    "weight_dist = torch.distributions.MultivariateNormal(\n",
    "    bnn_multi.conv1.mu_kernel.view(-1),\n",
    "    bnn_multi.conv1.get_covariance_matrix() + epslion * torch.eye(c_in * c_out * k * k).to(device)\n",
    ")\n",
    "\n",
    "w_bnn = weight_dist.rsample().reshape(6, 1, 3, 3).view(-1)\n",
    "w_dnn = dnn.conv1.weight.data.view(-1)\n",
    "\n",
    "# Visualize the difference using vertical lines\n",
    "plt.figure(figsize=(10, 5))\n",
    "x = range(len(w_dnn.cpu().detach().numpy()))\n",
    "\n",
    "# # Plot DNN weights with thicker lines\n",
    "# plt.vlines(x, ymin=0, ymax=w_dnn.cpu().detach().numpy(), color='r', linewidth=3, label='DNN')\n",
    "\n",
    "# # Plot BNN weights with thinner lines\n",
    "# plt.vlines(x, ymin=0, ymax=w_bnn.cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "# Plot differences\n",
    "\n",
    "plt.vlines(x, ymin=0, ymax=(w_dnn.cpu().detach() - w_bnn.cpu().detach()).abs(), color='r', linewidth=1, label='DNN - BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Randomly Initialized)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Diff (abs)')\n",
    "plt.ylim(0,3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cov = I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bnn_multi = LeNet_BNN().to(device)\n",
    "\n",
    "import copy\n",
    "cov_not_optimized = bnn_multi.conv1.get_covariance_matrix().cpu().detach().numpy()  \n",
    "print(cov_not_optimized.shape)\n",
    "optimizer = optim.Adam([bnn_multi.conv1.mu_kernel, bnn_multi.conv1.L_param], lr=1e-2)\n",
    "\n",
    "mu_log = []\n",
    "losses = []\n",
    "mean_loss = []\n",
    "for idx, _ in tqdm(enumerate(range(10000))):\n",
    "    w_conv1_dnn = dnn.conv1.weight.data.to(device)\n",
    "    c_in, c_out, k, _ = w_conv1_dnn.size()\n",
    "    \n",
    "    mu = bnn_multi.conv1.mu_kernel\n",
    "    mu_flat = mu.view(-1)\n",
    "    w_flat = w_conv1_dnn.view(-1)\n",
    "\n",
    "    epslion = 1e-6\n",
    "    cov = bnn_multi.conv1.get_covariance_matrix() + epslion * torch.eye(c_in * c_out * k * k).to(device)\n",
    "    \n",
    "    # Sampling the weight\n",
    "    w = torch.distributions.MultivariateNormal(mu_flat, torch.eye(c_in * c_out * k * k).to(device)).rsample().reshape(c_in, c_out, k, k)\n",
    "    \n",
    "    # k_value = torch.tensor(k, dtype=torch.float32).to(device)\n",
    "    # pi_value = torch.tensor(torch.pi, dtype=torch.float32).to(device)\n",
    "    # nnl = 0.5 * (k_value * torch.log(2 * pi_value) + torch.logdet(cov) + (w_flat - mu_flat).t() @ torch.inverse(cov) @ (w_flat - mu_flat))\n",
    "\n",
    "    nnl = (w - w_conv1_dnn).pow(2).mean()\n",
    "    optimizer.zero_grad()\n",
    "    nnl.backward()  # Do not use retain_graph=True\n",
    "    optimizer.step()\n",
    "\n",
    "    mu_log.append(mu.mean().item())\n",
    "    \n",
    "    losses.append(nnl.item())\n",
    "    \n",
    "    mean_loss.append(np.mean(losses))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(cov_not_optimized[:9,:9])\n",
    "plt.title('Covariance matrix (not optimized)')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "i=1\n",
    "plt.imshow(bnn_multi.conv1.get_covariance_matrix().cpu().detach().numpy()[:,:][:9*i,:9*i])\n",
    "plt.title('Covariance matrix (optimized)')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(mean_loss[:])\n",
    "plt.grid()\n",
    "plt.title('Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample the weights\n",
    "weight_dist = torch.distributions.MultivariateNormal(\n",
    "    bnn_multi.conv1.mu_kernel.view(-1),\n",
    "    torch.eye(c_in * c_out * k * k).to(device)\n",
    ")\n",
    "\n",
    "w_bnn = weight_dist.rsample().reshape(6, 1, 3, 3).view(-1)\n",
    "w_dnn = dnn.conv1.weight.data.view(-1)\n",
    "\n",
    "# Visualize the difference using vertical lines\n",
    "plt.figure(figsize=(10, 5))\n",
    "x = range(len(w_dnn.cpu().detach().numpy()))\n",
    "\n",
    "# # Plot DNN weights with thicker lines\n",
    "# plt.vlines(x, ymin=0, ymax=w_dnn.cpu().detach().numpy(), color='r', linewidth=3, label='DNN')\n",
    "\n",
    "# # Plot BNN weights with thinner lines\n",
    "# plt.vlines(x, ymin=0, ymax=w_bnn.cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.vlines(x, ymin=0, ymax=(w_bnn - w_dnn).abs().cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Cov = I)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Diff (Abs)')\n",
    "plt.ylim(0,3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# bnn_multi_not_trained = LeNet_BNN().to(device)\n",
    "\n",
    "# # Sample the weights\n",
    "# weight_dist = torch.distributions.MultivariateNormal(\n",
    "#     bnn_multi_not_trained.conv1.mu_kernel.view(-1),\n",
    "#     bnn_multi_not_trained.conv1.get_covariance_matrix()\n",
    "# )\n",
    "\n",
    "# w_bnn = weight_dist.rsample().reshape(6, 1, 3, 3).view(-1)\n",
    "# w_dnn = dnn.conv1.weight.data.view(-1)\n",
    "\n",
    "# # Visualize the difference using vertical lines\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# x = range(len(w_dnn.cpu().detach().numpy()))\n",
    "\n",
    "# # # Plot DNN weights with thicker lines\n",
    "# # plt.vlines(x, ymin=0, ymax=w_dnn.cpu().detach().numpy(), color='r', linewidth=3, label='DNN')\n",
    "\n",
    "# # # Plot BNN weights with thinner lines\n",
    "# # plt.vlines(x, ymin=0, ymax=w_bnn.cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "# # Plot differences\n",
    "# plt.vlines(x, ymin=0, ymax=(w_bnn - w_dnn).cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.title('DNN and BNN Weight Differences')\n",
    "# plt.xlabel('Weight Index')\n",
    "# plt.ylabel('Weight Value')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2개 일 때는 어떻게 될까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leanred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bnn_multi = LeNet_BNN().to(device)\n",
    "optimizer = optim.Adam(bnn_multi.parameters(), lr=1e-3)\n",
    "\n",
    "mu_log = []\n",
    "losses = []\n",
    "mean_loss = []\n",
    "for idx, _ in tqdm(enumerate(range(10000))):\n",
    "    w_conv1_dnn = dnn.conv1.weight.data.to(device)\n",
    "    w_conv2_dnn = dnn.conv2.weight.data.to(device)\n",
    "    \n",
    "    c_in_conv1, c_out_conv1, k_conv1, _ = w_conv1_dnn.size()\n",
    "    c_in_conv2, c_out_conv2, k_conv2, _ = w_conv2_dnn.size()\n",
    "    \n",
    "    mu_bnn_conv1 = bnn_multi.conv1.mu_kernel\n",
    "    mu_flat_conv1 = mu_bnn_conv1.view(-1)\n",
    "    \n",
    "    mu_bnn_conv2 = bnn_multi.conv2.mu_kernel\n",
    "    mu_flat_conv2 = mu_bnn_conv2.view(-1)\n",
    "    \n",
    "    w_flat_conv1 = w_conv1_dnn.view(-1)\n",
    "    w_flat_conv2 = w_conv2_dnn.view(-1)\n",
    "\n",
    "    epslion = 1e-6\n",
    "    cov_1 = bnn_multi.conv1.get_covariance_matrix() + epslion * torch.eye(c_in_conv1 * c_out_conv1 * k_conv1 * k_conv1).to(device)\n",
    "    cov_2 = bnn_multi.conv2.get_covariance_matrix() + epslion * torch.eye(c_in_conv2 * c_out_conv2 * k_conv2 * k_conv2).to(device)\n",
    "    \n",
    "    # Sampling the weight\n",
    "    w_bnn_conv1 = torch.distributions.MultivariateNormal(mu_flat_conv1, cov_1).rsample().reshape(c_in_conv1, c_out_conv1, k_conv1, k_conv1)\n",
    "    w_bnn_conv2 = torch.distributions.MultivariateNormal(mu_flat_conv2, cov_2).rsample().reshape(c_in_conv2, c_out_conv2, k_conv2, k_conv2)\n",
    "\n",
    "    nll = (w_bnn_conv1 - w_conv1_dnn).pow(2).mean()\n",
    "    nll += (w_bnn_conv2 - w_conv2_dnn).pow(2).mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    nll.backward()  # Do not use retain_graph=True\n",
    "    optimizer.step()\n",
    "\n",
    "    mu_log.append(mu.mean().item())\n",
    "    \n",
    "    losses.append(nll.item())\n",
    "    \n",
    "    mean_loss.append(np.mean(losses))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "# plt.subplot(1,3,1)\n",
    "# plt.imshow(cov_not_optimized[:9,:9])\n",
    "# plt.title('Covariance matrix (not optimized)')\n",
    "\n",
    "# plt.subplot(1,3,2)\n",
    "# i=1\n",
    "# plt.imshow(bnn_multi.conv1.get_covariance_matrix().cpu().detach().numpy()[:,:][:9*i,:9*i])\n",
    "# plt.title('Covariance matrix (optimized)')\n",
    "# plt.colorbar()\n",
    "# plt.subplot(1,3,3)\n",
    "plt.plot(mean_loss[:])\n",
    "plt.grid()\n",
    "plt.title('Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample the weights\n",
    "weight_dist_conv1 = torch.distributions.MultivariateNormal(\n",
    "    bnn_multi.conv1.mu_kernel.view(-1),\n",
    "    bnn_multi.conv1.get_covariance_matrix() +  epslion * torch.eye(c_in_conv1 * c_out_conv1 * k_conv1 * k_conv1).to(device)\n",
    ")\n",
    "\n",
    "w_bnn_conv1 = weight_dist_conv1.rsample().reshape(6, 1, 3, 3).view(-1)\n",
    "w_dnn_conv1 = dnn.conv1.weight.data.view(-1)\n",
    "\n",
    "weight_dist_conv2 = torch.distributions.MultivariateNormal(\n",
    "    bnn_multi.conv2.mu_kernel.view(-1),\n",
    "    bnn_multi.conv2.get_covariance_matrix() +  epslion * torch.eye(c_in_conv2 * c_out_conv2 * k_conv2 * k_conv2).to(device)\n",
    ")    \n",
    "\n",
    "w_bnn_conv2 = weight_dist_conv2.rsample().reshape(16, 6, 3, 3).view(-1)\n",
    "w_dnn_conv2 = dnn.conv2.weight.data.view(-1)\n",
    "\n",
    "# Visualize the difference using vertical lines\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2,2,1)\n",
    "x = range(len(w_dnn_conv1.cpu().detach().numpy()))\n",
    "\n",
    "# Plot DNN weights with thicker lines\n",
    "plt.vlines(x, ymin=0, ymax=w_dnn_conv1.cpu().detach().numpy(), color='r', linewidth=3, label='DNN')\n",
    "\n",
    "# Plot BNN weights with thinner lines\n",
    "plt.vlines(x, ymin=0, ymax=w_bnn_conv1.cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Conv1)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Weight Value')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "x = range(len(w_dnn_conv2.cpu().detach().numpy()))\n",
    "\n",
    "# Plot DNN weights with thicker lines\n",
    "plt.vlines(x, ymin=0, ymax=w_dnn_conv2.cpu().detach().numpy(), color='r', linewidth=3, label='DNN')\n",
    "\n",
    "# Plot BNN weights with thinner lines\n",
    "plt.vlines(x, ymin=0, ymax=w_bnn_conv2.cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Conv2)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Weight Value')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "x = range(len(w_dnn_conv1.cpu().detach().numpy()))\n",
    "\n",
    "# Plot differences\n",
    "plt.vlines(x, ymin=0, ymax=(w_bnn_conv1 - w_dnn_conv1).abs().cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Conv1)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Diff (Abs)')\n",
    "plt.ylim(0,3)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "x = range(len(w_dnn_conv2.cpu().detach().numpy()))\n",
    "\n",
    "# Plot differences\n",
    "plt.vlines(x, ymin=0, ymax=(w_bnn_conv2 - w_dnn_conv2).abs().cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Conv2)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Diff (Abs)')\n",
    "plt.ylim(0,3)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cov = I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bnn_multi = LeNet_BNN().to(device)\n",
    "optimizer = optim.Adam(bnn_multi.parameters(), lr=1e-3)\n",
    "\n",
    "mu_log = []\n",
    "losses = []\n",
    "mean_loss = []\n",
    "for idx, _ in tqdm(enumerate(range(10000))):\n",
    "    w_conv1_dnn = dnn.conv1.weight.data.to(device)\n",
    "    w_conv2_dnn = dnn.conv2.weight.data.to(device)\n",
    "    \n",
    "    c_in_conv1, c_out_conv1, k_conv1, _ = w_conv1_dnn.size()\n",
    "    c_in_conv2, c_out_conv2, k_conv2, _ = w_conv2_dnn.size()\n",
    "    \n",
    "    mu_bnn_conv1 = bnn_multi.conv1.mu_kernel\n",
    "    mu_flat_conv1 = mu_bnn_conv1.view(-1)\n",
    "    \n",
    "    mu_bnn_conv2 = bnn_multi.conv2.mu_kernel\n",
    "    mu_flat_conv2 = mu_bnn_conv2.view(-1)\n",
    "    \n",
    "    w_flat_conv1 = w_conv1_dnn.view(-1)\n",
    "    w_flat_conv2 = w_conv2_dnn.view(-1)\n",
    "\n",
    "    epslion = 1e-6\n",
    "    cov_1 = torch.eye(c_in_conv1 * c_out_conv1 * k_conv1 * k_conv1).to(device)\n",
    "    cov_2 = torch.eye(c_in_conv2 * c_out_conv2 * k_conv2 * k_conv2).to(device)\n",
    "    \n",
    "    # Sampling the weight\n",
    "    w_bnn_conv1 = torch.distributions.MultivariateNormal(mu_flat_conv1, cov_1).rsample().reshape(c_in_conv1, c_out_conv1, k_conv1, k_conv1)\n",
    "    w_bnn_conv2 = torch.distributions.MultivariateNormal(mu_flat_conv2, cov_2).rsample().reshape(c_in_conv2, c_out_conv2, k_conv2, k_conv2)\n",
    "\n",
    "    nll = (w_bnn_conv1 - w_conv1_dnn).pow(2).mean()\n",
    "    nll += (w_bnn_conv2 - w_conv2_dnn).pow(2).mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    nll.backward()  # Do not use retain_graph=True\n",
    "    optimizer.step()\n",
    "\n",
    "    mu_log.append(mu.mean().item())\n",
    "    \n",
    "    losses.append(nll.item())\n",
    "    \n",
    "    mean_loss.append(np.mean(losses))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "# plt.subplot(1,3,1)\n",
    "# plt.imshow(cov_not_optimized[:9,:9])\n",
    "# plt.title('Covariance matrix (not optimized)')\n",
    "\n",
    "# plt.subplot(1,3,2)\n",
    "# i=1\n",
    "# plt.imshow(bnn_multi.conv1.get_covariance_matrix().cpu().detach().numpy()[:,:][:9*i,:9*i])\n",
    "# plt.title('Covariance matrix (optimized)')\n",
    "# plt.colorbar()\n",
    "# plt.subplot(1,3,3)\n",
    "plt.plot(mean_loss[:])\n",
    "plt.grid()\n",
    "plt.title('Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample the weights\n",
    "weight_dist_conv1 = torch.distributions.MultivariateNormal(\n",
    "    bnn_multi.conv1.mu_kernel.view(-1),\n",
    "    torch.eye(c_in_conv1 * c_out_conv1 * k_conv1 * k_conv1).to(device)\n",
    ")\n",
    "\n",
    "w_bnn_conv1 = weight_dist_conv1.rsample().reshape(6, 1, 3, 3).view(-1)\n",
    "w_dnn_conv1 = dnn.conv1.weight.data.view(-1)\n",
    "\n",
    "weight_dist_conv2 = torch.distributions.MultivariateNormal(\n",
    "    bnn_multi.conv2.mu_kernel.view(-1),\n",
    "    torch.eye(c_in_conv2 * c_out_conv2 * k_conv2 * k_conv2).to(device)\n",
    ")    \n",
    "\n",
    "w_bnn_conv2 = weight_dist_conv2.rsample().reshape(16, 6, 3, 3).view(-1)\n",
    "w_dnn_conv2 = dnn.conv2.weight.data.view(-1)\n",
    "\n",
    "# Visualize the difference using vertical lines\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2,2,1)\n",
    "x = range(len(w_dnn_conv1.cpu().detach().numpy()))\n",
    "\n",
    "# Plot DNN weights with thicker lines\n",
    "plt.vlines(x, ymin=0, ymax=w_dnn_conv1.cpu().detach().numpy(), color='r', linewidth=3, label='DNN')\n",
    "\n",
    "# Plot BNN weights with thinner lines\n",
    "plt.vlines(x, ymin=0, ymax=w_bnn_conv1.cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Conv1)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Weight Value')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "x = range(len(w_dnn_conv2.cpu().detach().numpy()))\n",
    "\n",
    "# Plot DNN weights with thicker lines\n",
    "plt.vlines(x, ymin=0, ymax=w_dnn_conv2.cpu().detach().numpy(), color='r', linewidth=3, label='DNN')\n",
    "\n",
    "# Plot BNN weights with thinner lines\n",
    "plt.vlines(x, ymin=0, ymax=w_bnn_conv2.cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Conv2)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Weight Value')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "x = range(len(w_dnn_conv1.cpu().detach().numpy()))\n",
    "\n",
    "# Plot differences\n",
    "plt.vlines(x, ymin=0, ymax=(w_bnn_conv1 - w_dnn_conv1).abs().cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Conv1)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Diff (Abs)')\n",
    "plt.ylim(0,3)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "x = range(len(w_dnn_conv2.cpu().detach().numpy()))\n",
    "\n",
    "# Plot differences\n",
    "plt.vlines(x, ymin=0, ymax=(w_bnn_conv2 - w_dnn_conv2).abs().cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Conv2)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Diff (Abs)')\n",
    "plt.ylim(0,3)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cov randomly initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bnn_multi = LeNet_BNN().to(device)\n",
    "optimizer = optim.Adam([bnn_multi.conv1.mu_kernel, bnn_multi.conv2.mu_kernel], lr=1e-3)\n",
    "\n",
    "mu_log = []\n",
    "losses = []\n",
    "mean_loss = []\n",
    "for idx, _ in tqdm(enumerate(range(10000))):\n",
    "    w_conv1_dnn = dnn.conv1.weight.data.to(device)\n",
    "    w_conv2_dnn = dnn.conv2.weight.data.to(device)\n",
    "    \n",
    "    c_in_conv1, c_out_conv1, k_conv1, _ = w_conv1_dnn.size()\n",
    "    c_in_conv2, c_out_conv2, k_conv2, _ = w_conv2_dnn.size()\n",
    "    \n",
    "    mu_bnn_conv1 = bnn_multi.conv1.mu_kernel\n",
    "    mu_flat_conv1 = mu_bnn_conv1.view(-1)\n",
    "    \n",
    "    mu_bnn_conv2 = bnn_multi.conv2.mu_kernel\n",
    "    mu_flat_conv2 = mu_bnn_conv2.view(-1)\n",
    "    \n",
    "    w_flat_conv1 = w_conv1_dnn.view(-1)\n",
    "    w_flat_conv2 = w_conv2_dnn.view(-1)\n",
    "\n",
    "    epslion = 1e-6\n",
    "    cov_1 = torch.eye(c_in_conv1 * c_out_conv1 * k_conv1 * k_conv1).to(device)\n",
    "    cov_2 = torch.eye(c_in_conv2 * c_out_conv2 * k_conv2 * k_conv2).to(device)\n",
    "    \n",
    "    # Sampling the weight\n",
    "    w_bnn_conv1 = torch.distributions.MultivariateNormal(mu_flat_conv1, cov_1).rsample().reshape(c_in_conv1, c_out_conv1, k_conv1, k_conv1)\n",
    "    w_bnn_conv2 = torch.distributions.MultivariateNormal(mu_flat_conv2, cov_2).rsample().reshape(c_in_conv2, c_out_conv2, k_conv2, k_conv2)\n",
    "\n",
    "    nll = (w_bnn_conv1 - w_conv1_dnn).pow(2).mean()\n",
    "    nll += (w_bnn_conv2 - w_conv2_dnn).pow(2).mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    nll.backward()  # Do not use retain_graph=True\n",
    "    optimizer.step()\n",
    "\n",
    "    mu_log.append(mu.mean().item())\n",
    "    \n",
    "    losses.append(nll.item())\n",
    "    \n",
    "    mean_loss.append(np.mean(losses))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "# plt.subplot(1,3,1)\n",
    "# plt.imshow(cov_not_optimized[:9,:9])\n",
    "# plt.title('Covariance matrix (not optimized)')\n",
    "\n",
    "# plt.subplot(1,3,2)\n",
    "# i=1\n",
    "# plt.imshow(bnn_multi.conv1.get_covariance_matrix().cpu().detach().numpy()[:,:][:9*i,:9*i])\n",
    "# plt.title('Covariance matrix (optimized)')\n",
    "# plt.colorbar()\n",
    "# plt.subplot(1,3,3)\n",
    "plt.plot(mean_loss[:])\n",
    "plt.grid()\n",
    "plt.title('Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample the weights\n",
    "weight_dist_conv1 = torch.distributions.MultivariateNormal(\n",
    "    bnn_multi.conv1.mu_kernel.view(-1),\n",
    "    bnn_multi.conv1.get_covariance_matrix() +  epslion * torch.eye(c_in_conv1 * c_out_conv1 * k_conv1 * k_conv1).to(device)\n",
    ")\n",
    "\n",
    "w_bnn_conv1 = weight_dist_conv1.rsample().reshape(6, 1, 3, 3).view(-1)\n",
    "w_dnn_conv1 = dnn.conv1.weight.data.view(-1)\n",
    "\n",
    "weight_dist_conv2 = torch.distributions.MultivariateNormal(\n",
    "    bnn_multi.conv2.mu_kernel.view(-1),\n",
    "    bnn_multi.conv2.get_covariance_matrix() +  epslion * torch.eye(c_in_conv2 * c_out_conv2 * k_conv2 * k_conv2).to(device)\n",
    ")    \n",
    "\n",
    "w_bnn_conv2 = weight_dist_conv2.rsample().reshape(16, 6, 3, 3).view(-1)\n",
    "w_dnn_conv2 = dnn.conv2.weight.data.view(-1)\n",
    "\n",
    "# Visualize the difference using vertical lines\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2,2,1)\n",
    "x = range(len(w_dnn_conv1.cpu().detach().numpy()))\n",
    "\n",
    "# Plot DNN weights with thicker lines\n",
    "plt.vlines(x, ymin=0, ymax=w_dnn_conv1.cpu().detach().numpy(), color='r', linewidth=3, label='DNN')\n",
    "\n",
    "# Plot BNN weights with thinner lines\n",
    "plt.vlines(x, ymin=0, ymax=w_bnn_conv1.cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Conv1)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Weight Value')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "x = range(len(w_dnn_conv2.cpu().detach().numpy()))\n",
    "\n",
    "# Plot DNN weights with thicker lines\n",
    "plt.vlines(x, ymin=0, ymax=w_dnn_conv2.cpu().detach().numpy(), color='r', linewidth=3, label='DNN')\n",
    "\n",
    "# Plot BNN weights with thinner lines\n",
    "plt.vlines(x, ymin=0, ymax=w_bnn_conv2.cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Conv2)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Weight Value')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "x = range(len(w_dnn_conv1.cpu().detach().numpy()))\n",
    "\n",
    "# Plot differences\n",
    "plt.vlines(x, ymin=0, ymax=(w_bnn_conv1 - w_dnn_conv1).abs().cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Conv1)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Diff (Abs)')\n",
    "plt.ylim(0,3)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "x = range(len(w_dnn_conv2.cpu().detach().numpy()))\n",
    "\n",
    "# Plot differences\n",
    "plt.vlines(x, ymin=0, ymax=(w_bnn_conv2 - w_dnn_conv2).abs().cpu().detach().numpy(), color='b', linewidth=1, label='BNN')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('DNN and BNN Weight Differences (Conv2)')\n",
    "plt.xlabel('Weight Index')\n",
    "plt.ylabel('Diff (Abs)')\n",
    "plt.ylim(0,3)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Prior distribution using the learned covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9853, 0.04415414296090603)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn = LeNet().to(device)\n",
    "dnn.load_state_dict(torch.load('runs/dnn_bs1024_lr0.001_mc100_ep100_20240710-202543/best_model.pth'))\n",
    "\n",
    "test_DNN(dnn, test_loader,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [01:03, 157.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bnn_multi = LeNet_BNN().to(device)\n",
    "optimizer = optim.Adam(bnn_multi.parameters(), lr=1e-3)\n",
    "\n",
    "mu_log = []\n",
    "losses = []\n",
    "mean_loss = []\n",
    "for idx, _ in tqdm(enumerate(range(10000))):\n",
    "    w_conv1_dnn = dnn.conv1.weight.data.to(device)\n",
    "    w_conv2_dnn = dnn.conv2.weight.data.to(device)\n",
    "    \n",
    "    c_in_conv1, c_out_conv1, k_conv1, _ = w_conv1_dnn.size()\n",
    "    c_in_conv2, c_out_conv2, k_conv2, _ = w_conv2_dnn.size()\n",
    "    \n",
    "    mu_bnn_conv1 = bnn_multi.conv1.mu_kernel\n",
    "    mu_flat_conv1 = mu_bnn_conv1.view(-1)\n",
    "    \n",
    "    mu_bnn_conv2 = bnn_multi.conv2.mu_kernel\n",
    "    mu_flat_conv2 = mu_bnn_conv2.view(-1)\n",
    "    \n",
    "    w_flat_conv1 = w_conv1_dnn.view(-1)\n",
    "    w_flat_conv2 = w_conv2_dnn.view(-1)\n",
    "\n",
    "    epslion = 1e-6\n",
    "    cov_1 = bnn_multi.conv1.get_covariance_matrix() + epslion * torch.eye(c_in_conv1 * c_out_conv1 * k_conv1 * k_conv1).to(device)\n",
    "    cov_2 = bnn_multi.conv2.get_covariance_matrix() + epslion * torch.eye(c_in_conv2 * c_out_conv2 * k_conv2 * k_conv2).to(device)\n",
    "    \n",
    "    # Sampling the weight\n",
    "    w_bnn_conv1 = torch.distributions.MultivariateNormal(mu_flat_conv1, cov_1).rsample().reshape(c_in_conv1, c_out_conv1, k_conv1, k_conv1)\n",
    "    w_bnn_conv2 = torch.distributions.MultivariateNormal(mu_flat_conv2, cov_2).rsample().reshape(c_in_conv2, c_out_conv2, k_conv2, k_conv2)\n",
    "\n",
    "    nll = (w_bnn_conv1 - w_conv1_dnn).pow(2).mean()\n",
    "    nll += (w_bnn_conv2 - w_conv2_dnn).pow(2).mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    nll.backward()  # Do not use retain_graph=True\n",
    "    optimizer.step()\n",
    "\n",
    "    mu_log.append(mu_flat_conv1.mean().item() + mu_flat_conv2.mean().item())\n",
    "    \n",
    "    losses.append(nll.item())\n",
    "    \n",
    "    mean_loss.append(np.mean(losses))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "# plt.subplot(1,3,1)\n",
    "# plt.imshow(cov_not_optimized[:9,:9])\n",
    "# plt.title('Covariance matrix (not optimized)')\n",
    "\n",
    "# plt.subplot(1,3,2)\n",
    "# i=1\n",
    "# plt.imshow(bnn_multi.conv1.get_covariance_matrix().cpu().detach().numpy()[:,:][:9*i,:9*i])\n",
    "# plt.title('Covariance matrix (optimized)')\n",
    "# plt.colorbar()\n",
    "# plt.subplot(1,3,3)\n",
    "plt.plot(mean_loss[:])\n",
    "plt.grid()\n",
    "plt.title('Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m[Train] Epoch: 0/100, Acc: 0.39360, NNL: 6.13417 KL: 251.14269\u001b[0m: : 22it [00:44,  1.99s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "bnn_with_good_prior = LeNet_BNN().to(device) \n",
    "\n",
    "'''\n",
    "bnn_with_good_prior.conv1.prior_mean = bnn.conv1.mu_kernel.detach().clone().flatten()\n",
    "bnn_with_good_prior.conv1.prior_variance = bnn_with_good_prior.conv1.get_covariance_matrix(bnn.conv1.L_param.detach().clone(), bnn.conv1.B_param.detach().clone())\n",
    "\n",
    "'''\n",
    "bnn_with_good_prior.conv1.prior_mean = bnn_multi.conv1.mu_kernel.detach().clone().flatten()\n",
    "bnn_with_good_prior.conv1.prior_variance = bnn_multi.conv1.get_covariance_matrix().detach().clone()\n",
    "\n",
    "# bnn_with_good_prior.conv2.prior_mean = bnn_multi.conv2.mu_kernel.view(-1).detach().clone()\n",
    "# bnn_with_good_prior.conv2.prior_variance = (bnn_multi.conv2.L_param.T @ bnn_multi.conv2.L_param).detach().clone()\n",
    "\n",
    "bnn_with_good_prior.fc1 = dnn.fc1\n",
    "\n",
    "class args:\n",
    "    pass\n",
    "args = args()\n",
    "args.t = 1.0\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(f'runs/bnn_with_good_prior_multi')\n",
    "train_BNN(epoch= 100, model = bnn_with_good_prior.cuda(), train_loader= train_loader, test_loader= test_loader, optimizer= optim.Adam(bnn_with_good_prior.parameters(), lr=1e-3), writer = writer, mc_runs = 100, bs = 1024, device = 'cuda', args=args, moped=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the weights\n",
    "\n",
    "# loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam([bnn_multi.conv1.mu_kernel, bnn_multi.conv1.L_param, bnn_multi.conv1.B_param], lr=1e-3)\n",
    "\n",
    "# Log for plotting\n",
    "mu_log = []\n",
    "sigma_log = []\n",
    "losses = []\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    mu = bnn_multi.conv1.mu_kernel\n",
    "    sigma = bnn_multi.conv1.get_covariance_matrix(bnn_multi.conv1.L_param, bnn_multi.conv1.B_param)\n",
    "\n",
    "    k = \n",
    "    loss_val = 0.5 * (k * torch.log(2 * torch.pi) + torch.log(cov_det) + mahalanobis_dist)\n",
    "    # loss_val = 0.5 * torch.mean((mu - w_conv1_dnn)**2 / sigma + sigma )\n",
    "        \n",
    "        \n",
    "    \n",
    "    # loss_val = loss(w, w_conv1_dnn)\n",
    "    optimizer.zero_grad()\n",
    "    loss_val.backward()\n",
    "    optimizer.step()\n",
    "    mu_log.append(mu.mean().item())\n",
    "    sigma_log.append(sigma.mean().item())\n",
    "    losses.append(loss_val.item())\n",
    "    \n",
    "# plot training progress\n",
    "plt.plot(losses)\n",
    "plt.plot(mu_log)\n",
    "plt.plot(sigma_log)\n",
    "plt.grid()\n",
    "plt.legend(['loss', 'mu', 'sigma'])\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# 예시 데이터, 실제 데이터로 대체하세요.\n",
    "mu_kernel = bnn_uni.conv1.mu_kernel  # 실제 mu_kernel 값으로 대체\n",
    "rho_kernel = bnn_uni.conv1.rho_kernel  # 실제 rho_kernel 값으로 대체\n",
    "w_dnn = dnn.conv1.weight.data\n",
    "# sigma_weight 계산\n",
    "sigma_weight = torch.log1p(torch.exp(rho_kernel))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for idx, (w_target, mu, sigma) in enumerate(zip(w_dnn, mu_kernel, sigma_weight)):\n",
    "    \n",
    "    print(w_target.shape, mu.shape, sigma.shape)\n",
    "    w_target = w_target.cpu().detach().numpy()\n",
    "    plt.subplot(6,1, idx+1)\n",
    "    for i in range(3):\n",
    "        \n",
    "        for j in range(3):\n",
    "            \n",
    "            plt.axvline(x=w_target[0,i,j], color='r', linestyle='--', label='target')\n",
    "            \n",
    "            x = np.linspace(mu[0,i,j].item() - 3 * sigma[0,i,j].item(), mu[0,i,j].item() + 3 * sigma[0,i,j].item(), 1000)\n",
    "            pdf = norm.pdf(x, loc=mu[0,i,j].item(), scale= sigma[0,i,j].item())\n",
    "            # plt.subplot(3,3,i+j+1)\n",
    "\n",
    "            plt.plot(x, pdf, label=f'N({mu[0,i,j].item():.2f}, {sigma[0,i,j].item():.2f})')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian_torch.layers.variational_layers.conv_variational_layers import Conv2dReparameterization_Multivariate\n",
    "\n",
    "# Hook 함수 정의\n",
    "def hook_fn(module, input, output):\n",
    "    if isinstance(module, Conv2dReparameterization_Multivariate):\n",
    "        if module == bnn.conv1:\n",
    "            bnn_conv1_out.append(output)\n",
    "        elif module == bnn.conv2:\n",
    "            bnn_conv2_out.append(output)\n",
    "    # elif isinstance(module, nn.AvgPool2d):\n",
    "    #     bnn_pool_out.append(output)\n",
    "\n",
    "\n",
    "# 모델 초기화\n",
    "# dnn = LeNet()\n",
    "bnn = LeNet_BNN()  # 실제로는 Bayesian Neural Network여야 함\n",
    "\n",
    "# Hook을 저장할 리스트\n",
    "dnn_conv1_out = []\n",
    "dnn_conv2_out = []\n",
    "dnn_pool_out = []\n",
    "bnn_conv1_out = []\n",
    "bnn_conv2_out = []\n",
    "bnn_pool_out = []\n",
    "\n",
    "# Hook 등록\n",
    "dnn.conv1.register_forward_hook(lambda m, i, o: dnn_conv1_out.append(o))\n",
    "dnn.conv2.register_forward_hook(lambda m, i, o: dnn_conv2_out.append(o))\n",
    "dnn.pool.register_forward_hook(lambda m, i, o: dnn_pool_out.append(o))\n",
    "\n",
    "bnn.conv1.register_forward_hook(hook_fn)\n",
    "bnn.conv2.register_forward_hook(hook_fn)\n",
    "bnn.pool.register_forward_hook(hook_fn)\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer = torch.optim.Adam(bnn.parameters(), lr=1e-3)#, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Knowledge Distillation 학습 루프\n",
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    pbar = tqdm(enumerate(train_loader))\n",
    "    dnn.eval().cuda()\n",
    "    bnn.train().cuda()\n",
    "    \n",
    "    losses = []\n",
    "    for batch_idx, (data, target) in pbar:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            dnn_conv1_out.clear()\n",
    "            dnn_conv2_out.clear()\n",
    "            dnn_pool_out.clear()\n",
    "            \n",
    "            y_t = dnn(data)\n",
    "            # output_t = [dnn_conv1_out[0], dnn_conv2_out[0], y_t]\n",
    "            output_t = [dnn_conv1_out[0]]\n",
    "            \n",
    "        bnn_conv1_out.clear()\n",
    "        bnn_conv2_out.clear()\n",
    "        bnn_pool_out.clear()\n",
    "        \n",
    "        y_s, _ = bnn(data)\n",
    "        # output_s = [bnn_conv1_out[0][0], bnn_conv2_out[0][0], y_s]\n",
    "        output_s = [bnn_conv1_out[0][0]]\n",
    "        \n",
    "        loss = 0\n",
    "        for idx, (t, s) in enumerate(zip(output_t, output_s)):\n",
    "            loss += F.mse_loss(s, t)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pbar.set_description(f\"Loss: {np.mean(losses):.3f} Epoch: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the covariance matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "conv1_cov = bnn.conv1.get_covariance_matrix(bnn.conv1.L_param, bnn.conv1.B_param).cpu().detach().numpy()\n",
    "# conv2_cov = bnn.conv2.get_covariance_matrix(bnn.conv2.L_param, bnn.conv2.B_param).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(conv1_cov[:9*i,:9*i], cmap='plasma')\n",
    "\n",
    "i=9\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(conv1_cov[:9*i,:9*i], cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bnn_with_good_prior = LeNet_BNN()\n",
    "bnn_with_good_prior.conv1.prior_mean = bnn.conv1.mu_kernel.detach().clone().flatten()\n",
    "bnn_with_good_prior.conv1.prior_variance = bnn_with_good_prior.conv1.get_covariance_matrix(bnn.conv1.L_param.detach().clone(), bnn.conv1.B_param.detach().clone())\n",
    "\n",
    "# bnn_with_good_prior.conv2.prior_mean = bnn.conv2.mu_kernel.detach().clone().flatten()\n",
    "# bnn_with_good_prior.conv2.prior_variance = bnn_with_good_prior.conv2.get_covariance_matrix(bnn.conv2.L_param.detach().clone(), bnn.conv2.B_param.detach().clone())\n",
    "\n",
    "train_BNN(10, bnn_with_good_prior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the covariance matrix\n",
    "import matplotlib.pyplot as plt\n",
    "conv1_cov = naiive_bnn.conv1.get_covariance_matrix(naiive_bnn.conv1.L_param, naiive_bnn.conv1.B_param).cpu().detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(conv1_cov[:,:], cmap='plasma')\n",
    "\n",
    "conv1_cov2 = bnn_with_good_prior.conv1.get_covariance_matrix(bnn_with_good_prior.conv1.L_param, bnn_with_good_prior.conv1.B_param).cpu().detach().numpy()\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(conv1_cov2[:,:], cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
